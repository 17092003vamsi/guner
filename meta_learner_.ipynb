{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+dPw3v2C72xGZjUjGPWc9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17092003vamsi/guner/blob/main/meta_learner_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tTuoOOrC7wa",
        "outputId": "efc1b21a-a74b-40db-c6b8-15ce645c19d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 577ms/step - accuracy: 0.2008 - loss: -2.8707 - val_accuracy: 0.2032 - val_loss: 0.5901 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 580ms/step - accuracy: 0.2023 - loss: -8.3082 - val_accuracy: 0.2086 - val_loss: -4.7231 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 494ms/step - accuracy: 0.1969 - loss: -12.6303 - val_accuracy: 0.2086 - val_loss: -10.5782 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.2090 - loss: -17.5004 - val_accuracy: 0.2139 - val_loss: -12.6964 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 599ms/step - accuracy: 0.1768 - loss: -22.5296 - val_accuracy: 0.2406 - val_loss: -18.5986 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - accuracy: 0.1890 - loss: -27.3282 - val_accuracy: 0.2406 - val_loss: -24.4526 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 503ms/step - accuracy: 0.1813 - loss: -34.5129 - val_accuracy: 0.2406 - val_loss: -29.3879 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 591ms/step - accuracy: 0.1644 - loss: -39.0278 - val_accuracy: 0.2567 - val_loss: -40.5238 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 569ms/step - accuracy: 0.1753 - loss: -47.4368 - val_accuracy: 0.2513 - val_loss: -47.9825 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 519ms/step - accuracy: 0.1961 - loss: -56.4846 - val_accuracy: 0.2674 - val_loss: -59.0744 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 596ms/step - accuracy: 0.1749 - loss: -63.1833 - val_accuracy: 0.2567 - val_loss: -63.3519 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 581ms/step - accuracy: 0.1907 - loss: -70.5640 - val_accuracy: 0.2781 - val_loss: -87.7346 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 591ms/step - accuracy: 0.2006 - loss: -81.1506 - val_accuracy: 0.2620 - val_loss: -100.5818 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 563ms/step - accuracy: 0.1975 - loss: -91.3042 - val_accuracy: 0.2299 - val_loss: -115.8316 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 497ms/step - accuracy: 0.1783 - loss: -100.6440 - val_accuracy: 0.2781 - val_loss: -124.1678 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 551ms/step - accuracy: 0.1896 - loss: -110.0672 - val_accuracy: 0.2246 - val_loss: -140.3502 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 674ms/step - accuracy: 0.1820 - loss: -122.5828 - val_accuracy: 0.2727 - val_loss: -150.6260 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 493ms/step - accuracy: 0.1950 - loss: -133.0606 - val_accuracy: 0.2620 - val_loss: -169.3625 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 588ms/step - accuracy: 0.2036 - loss: -139.7151 - val_accuracy: 0.2139 - val_loss: -179.2652 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 574ms/step - accuracy: 0.2146 - loss: -156.6781 - val_accuracy: 0.2086 - val_loss: -203.7833 - learning_rate: 0.0010\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Meta-Learner Accuracy: 0.42245989304812837\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.42      0.58        31\n",
            "           1       1.00      0.88      0.93        32\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.25      1.00      0.40        27\n",
            "           4       0.31      0.38      0.34        29\n",
            "           5       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.42       187\n",
            "   macro avg       0.41      0.45      0.37       187\n",
            "weighted avg       0.41      0.42      0.37       187\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv('project 2 sap.csv')  # Adjust file path if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Lable'].values)\n",
        "X = data.drop(columns=['Lable'])\n",
        "\n",
        "# Identify and handle non-numeric columns\n",
        "# You may need to adapt this based on your specific data and desired handling\n",
        "for column in X.columns:\n",
        "    if X[column].dtype == object:  # Check if the column is of object type (likely string)\n",
        "        try:\n",
        "            # Attempt to convert to numeric, coercing errors to NaN\n",
        "            X[column] = pd.to_numeric(X[column], errors='coerce')\n",
        "        except ValueError:\n",
        "            # If conversion fails, handle appropriately (e.g., drop, fill with a value, or encode)\n",
        "            print(f\"Column '{column}' contains non-numeric values. Consider dropping, filling, or encoding.\")\n",
        "            # Example: Drop the column\n",
        "            # X = X.drop(columns=[column])\n",
        "\n",
        "# Now convert to numpy array after handling non-numeric columns\n",
        "X = X.values\n",
        "\n",
        "# Replace NaNs with a fixed value or use imputation\n",
        "X = np.nan_to_num(X)\n",
        "\n",
        "# Ensure data is in a supported float type (e.g., float32)\n",
        "X = X.astype(np.float32)  # Convert to float32\n",
        "\n",
        "# ... (Rest of your code remains the same) ...\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# CNN Model\n",
        "def build_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),  # Use Input layer here\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Preprocess data for CNN\n",
        "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_val_cnn = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "cnn_model = build_cnn_model((X_train.shape[1], 1))\n",
        "cnn_model.fit(X_train_cnn, y_train, validation_data=(X_val_cnn, y_val), epochs=20, batch_size=32,\n",
        "              callbacks=[EarlyStopping(monitor='val_loss', patience=5), ReduceLROnPlateau()])\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions for Meta-Learner\n",
        "cnn_val_preds = cnn_model.predict(X_val_cnn).flatten()\n",
        "rf_val_preds = rf_model.predict_proba(X_val)[:, 1]\n",
        "meta_X_val = np.vstack((cnn_val_preds, rf_val_preds)).T\n",
        "\n",
        "cnn_test_preds = cnn_model.predict(X_test_cnn).flatten()\n",
        "rf_test_preds = rf_model.predict_proba(X_test)[:, 1]\n",
        "meta_X_test = np.vstack((cnn_test_preds, rf_test_preds)).T\n",
        "\n",
        "# Meta-Learner Model\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(meta_X_val, y_val)\n",
        "\n",
        "# Final Predictions and Evaluation\n",
        "meta_test_preds = meta_model.predict(meta_X_test)\n",
        "print(\"Meta-Learner Accuracy:\", accuracy_score(y_test, meta_test_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, meta_test_preds))\n"
      ]
    }
  ]
}