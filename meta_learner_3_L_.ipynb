{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZihEand2fEBTxOszggX1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17092003vamsi/guner/blob/main/meta_learner_3_L_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tTuoOOrC7wa",
        "outputId": "efc1b21a-a74b-40db-c6b8-15ce645c19d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 577ms/step - accuracy: 0.2008 - loss: -2.8707 - val_accuracy: 0.2032 - val_loss: 0.5901 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 580ms/step - accuracy: 0.2023 - loss: -8.3082 - val_accuracy: 0.2086 - val_loss: -4.7231 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 494ms/step - accuracy: 0.1969 - loss: -12.6303 - val_accuracy: 0.2086 - val_loss: -10.5782 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 528ms/step - accuracy: 0.2090 - loss: -17.5004 - val_accuracy: 0.2139 - val_loss: -12.6964 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 599ms/step - accuracy: 0.1768 - loss: -22.5296 - val_accuracy: 0.2406 - val_loss: -18.5986 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 518ms/step - accuracy: 0.1890 - loss: -27.3282 - val_accuracy: 0.2406 - val_loss: -24.4526 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 503ms/step - accuracy: 0.1813 - loss: -34.5129 - val_accuracy: 0.2406 - val_loss: -29.3879 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 591ms/step - accuracy: 0.1644 - loss: -39.0278 - val_accuracy: 0.2567 - val_loss: -40.5238 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 569ms/step - accuracy: 0.1753 - loss: -47.4368 - val_accuracy: 0.2513 - val_loss: -47.9825 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 519ms/step - accuracy: 0.1961 - loss: -56.4846 - val_accuracy: 0.2674 - val_loss: -59.0744 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 596ms/step - accuracy: 0.1749 - loss: -63.1833 - val_accuracy: 0.2567 - val_loss: -63.3519 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 581ms/step - accuracy: 0.1907 - loss: -70.5640 - val_accuracy: 0.2781 - val_loss: -87.7346 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 591ms/step - accuracy: 0.2006 - loss: -81.1506 - val_accuracy: 0.2620 - val_loss: -100.5818 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 563ms/step - accuracy: 0.1975 - loss: -91.3042 - val_accuracy: 0.2299 - val_loss: -115.8316 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 497ms/step - accuracy: 0.1783 - loss: -100.6440 - val_accuracy: 0.2781 - val_loss: -124.1678 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 551ms/step - accuracy: 0.1896 - loss: -110.0672 - val_accuracy: 0.2246 - val_loss: -140.3502 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 674ms/step - accuracy: 0.1820 - loss: -122.5828 - val_accuracy: 0.2727 - val_loss: -150.6260 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 493ms/step - accuracy: 0.1950 - loss: -133.0606 - val_accuracy: 0.2620 - val_loss: -169.3625 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 588ms/step - accuracy: 0.2036 - loss: -139.7151 - val_accuracy: 0.2139 - val_loss: -179.2652 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 574ms/step - accuracy: 0.2146 - loss: -156.6781 - val_accuracy: 0.2086 - val_loss: -203.7833 - learning_rate: 0.0010\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Meta-Learner Accuracy: 0.42245989304812837\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.42      0.58        31\n",
            "           1       1.00      0.88      0.93        32\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.25      1.00      0.40        27\n",
            "           4       0.31      0.38      0.34        29\n",
            "           5       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.42       187\n",
            "   macro avg       0.41      0.45      0.37       187\n",
            "weighted avg       0.41      0.42      0.37       187\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv('project 2 sap.csv')  # Adjust file path if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Lable'].values)\n",
        "X = data.drop(columns=['Lable'])\n",
        "\n",
        "# Identify and handle non-numeric columns\n",
        "# You may need to adapt this based on your specific data and desired handling\n",
        "for column in X.columns:\n",
        "    if X[column].dtype == object:  # Check if the column is of object type (likely string)\n",
        "        try:\n",
        "            # Attempt to convert to numeric, coercing errors to NaN\n",
        "            X[column] = pd.to_numeric(X[column], errors='coerce')\n",
        "        except ValueError:\n",
        "            # If conversion fails, handle appropriately (e.g., drop, fill with a value, or encode)\n",
        "            print(f\"Column '{column}' contains non-numeric values. Consider dropping, filling, or encoding.\")\n",
        "            # Example: Drop the column\n",
        "            # X = X.drop(columns=[column])\n",
        "\n",
        "# Now convert to numpy array after handling non-numeric columns\n",
        "X = X.values\n",
        "\n",
        "# Replace NaNs with a fixed value or use imputation\n",
        "X = np.nan_to_num(X)\n",
        "\n",
        "# Ensure data is in a supported float type (e.g., float32)\n",
        "X = X.astype(np.float32)  # Convert to float32\n",
        "\n",
        "# ... (Rest of your code remains the same) ...\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# CNN Model\n",
        "def build_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),  # Use Input layer here\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Preprocess data for CNN\n",
        "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_val_cnn = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "cnn_model = build_cnn_model((X_train.shape[1], 1))\n",
        "cnn_model.fit(X_train_cnn, y_train, validation_data=(X_val_cnn, y_val), epochs=20, batch_size=32,\n",
        "              callbacks=[EarlyStopping(monitor='val_loss', patience=5), ReduceLROnPlateau()])\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions for Meta-Learner\n",
        "cnn_val_preds = cnn_model.predict(X_val_cnn).flatten()\n",
        "rf_val_preds = rf_model.predict_proba(X_val)[:, 1]\n",
        "meta_X_val = np.vstack((cnn_val_preds, rf_val_preds)).T\n",
        "\n",
        "cnn_test_preds = cnn_model.predict(X_test_cnn).flatten()\n",
        "rf_test_preds = rf_model.predict_proba(X_test)[:, 1]\n",
        "meta_X_test = np.vstack((cnn_test_preds, rf_test_preds)).T\n",
        "\n",
        "# Meta-Learner Model\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(meta_X_val, y_val)\n",
        "\n",
        "# Final Predictions and Evaluation\n",
        "meta_test_preds = meta_model.predict(meta_X_test)\n",
        "print(\"Meta-Learner Accuracy:\", accuracy_score(y_test, meta_test_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, meta_test_preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression  # Changed to LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv('project 2 sap.csv')  # Adjust file path if needed\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['Lable'].values)\n",
        "X = data.drop(columns=['Lable'])\n",
        "\n",
        "# Identify and handle non-numeric columns\n",
        "for column in X.columns:\n",
        "    if X[column].dtype == object:\n",
        "        try:\n",
        "            X[column] = pd.to_numeric(X[column], errors='coerce')\n",
        "        except ValueError:\n",
        "            print(f\"Column '{column}' contains non-numeric values. Consider dropping, filling, or encoding.\")\n",
        "\n",
        "X = X.values\n",
        "X = np.nan_to_num(X)\n",
        "X = X.astype(np.float32)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "# CNN Model\n",
        "def build_cnn_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Dropout(0.25),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Preprocess data for CNN\n",
        "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_val_cnn = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "cnn_model = build_cnn_model((X_train.shape[1], 1))\n",
        "cnn_model.fit(X_train_cnn, y_train, validation_data=(X_val_cnn, y_val), epochs=20, batch_size=32,\n",
        "              callbacks=[EarlyStopping(monitor='val_loss', patience=5), ReduceLROnPlateau()])\n",
        "\n",
        "# Evaluate CNN model\n",
        "cnn_test_preds = (cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\").flatten()\n",
        "cnn_accuracy = accuracy_score(y_test, cnn_test_preds)\n",
        "print(\"CNN Model Accuracy:\", cnn_accuracy)\n",
        "print(\"CNN Classification Report:\\n\", classification_report(y_test, cnn_test_preds))\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "rf_test_preds = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_test_preds)\n",
        "print(\"Random Forest Model Accuracy:\", rf_accuracy)\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_test_preds))\n",
        "\n",
        "# Predictions for Meta-Learner\n",
        "cnn_val_preds = cnn_model.predict(X_val_cnn).flatten()\n",
        "rf_val_preds = rf_model.predict_proba(X_val)[:, 1]\n",
        "meta_X_val = np.vstack((cnn_val_preds, rf_val_preds)).T\n",
        "\n",
        "cnn_test_preds_meta = cnn_model.predict(X_test_cnn).flatten()\n",
        "rf_test_preds_meta = rf_model.predict_proba(X_test)[:, 1]\n",
        "meta_X_test = np.vstack((cnn_test_preds_meta, rf_test_preds_meta)).T\n",
        "\n",
        "# Meta-Learner Model with Linear Regression\n",
        "meta_model = LinearRegression()\n",
        "meta_model.fit(meta_X_val, y_val)\n",
        "\n",
        "# Make predictions with the meta-learner and convert them to binary (0 or 1)\n",
        "meta_test_preds = (meta_model.predict(meta_X_test) > 0.5).astype(int)\n",
        "\n",
        "# Evaluate Meta-Learner model\n",
        "meta_accuracy = accuracy_score(y_test, meta_test_preds)\n",
        "print(\"Meta-Learner (Linear Regression) Accuracy:\", meta_accuracy)\n",
        "print(\"Meta-Learner Classification Report:\\n\", classification_report(y_test, meta_test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEabwYvAIc1z",
        "outputId": "84e0c7b1-ebad-4348-ffe5-2b560445ffd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 622ms/step - accuracy: 0.2002 - loss: -2.6186 - val_accuracy: 0.2032 - val_loss: 8.3624 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 975ms/step - accuracy: 0.2168 - loss: -7.8799 - val_accuracy: 0.2086 - val_loss: -5.9010 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 745ms/step - accuracy: 0.2180 - loss: -13.6955 - val_accuracy: 0.2086 - val_loss: -8.3001 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 600ms/step - accuracy: 0.2043 - loss: -17.4865 - val_accuracy: 0.2139 - val_loss: -12.6827 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 486ms/step - accuracy: 0.1877 - loss: -21.6416 - val_accuracy: 0.2246 - val_loss: -15.9097 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 562ms/step - accuracy: 0.1770 - loss: -27.2295 - val_accuracy: 0.2246 - val_loss: -20.6384 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 592ms/step - accuracy: 0.1933 - loss: -35.1804 - val_accuracy: 0.2299 - val_loss: -32.0241 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 535ms/step - accuracy: 0.2080 - loss: -41.0241 - val_accuracy: 0.2460 - val_loss: -42.1120 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 615ms/step - accuracy: 0.1982 - loss: -48.0964 - val_accuracy: 0.2567 - val_loss: -47.2810 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 507ms/step - accuracy: 0.1952 - loss: -55.6077 - val_accuracy: 0.2460 - val_loss: -62.2086 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.1851 - loss: -64.8620 - val_accuracy: 0.2406 - val_loss: -71.4034 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 624ms/step - accuracy: 0.1886 - loss: -70.2264 - val_accuracy: 0.2834 - val_loss: -86.2286 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 585ms/step - accuracy: 0.1673 - loss: -82.3489 - val_accuracy: 0.2834 - val_loss: -98.6300 - learning_rate: 0.0010\n",
            "Epoch 14/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 497ms/step - accuracy: 0.1665 - loss: -87.1192 - val_accuracy: 0.2834 - val_loss: -111.4889 - learning_rate: 0.0010\n",
            "Epoch 15/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 600ms/step - accuracy: 0.1690 - loss: -97.7403 - val_accuracy: 0.2781 - val_loss: -129.1388 - learning_rate: 0.0010\n",
            "Epoch 16/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 599ms/step - accuracy: 0.1804 - loss: -111.9995 - val_accuracy: 0.2139 - val_loss: -149.9273 - learning_rate: 0.0010\n",
            "Epoch 17/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 594ms/step - accuracy: 0.1912 - loss: -118.1691 - val_accuracy: 0.2834 - val_loss: -154.3253 - learning_rate: 0.0010\n",
            "Epoch 18/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 605ms/step - accuracy: 0.1993 - loss: -130.8410 - val_accuracy: 0.2727 - val_loss: -165.8264 - learning_rate: 0.0010\n",
            "Epoch 19/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 549ms/step - accuracy: 0.1969 - loss: -149.0720 - val_accuracy: 0.2834 - val_loss: -187.3481 - learning_rate: 0.0010\n",
            "Epoch 20/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 516ms/step - accuracy: 0.2315 - loss: -155.2896 - val_accuracy: 0.2781 - val_loss: -197.6241 - learning_rate: 0.0010\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step\n",
            "CNN Model Accuracy: 0.27807486631016043\n",
            "CNN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82        31\n",
            "           1       0.17      0.84      0.29        32\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.00      0.00      0.00        27\n",
            "           4       0.00      0.00      0.00        29\n",
            "           5       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.28       187\n",
            "   macro avg       0.17      0.28      0.18       187\n",
            "weighted avg       0.17      0.28      0.18       187\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Accuracy: 0.9411764705882353\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        31\n",
            "           1       0.97      0.94      0.95        32\n",
            "           2       0.89      0.94      0.92        36\n",
            "           3       1.00      0.96      0.98        27\n",
            "           4       0.92      0.83      0.87        29\n",
            "           5       0.91      0.97      0.94        32\n",
            "\n",
            "    accuracy                           0.94       187\n",
            "   macro avg       0.94      0.94      0.94       187\n",
            "weighted avg       0.94      0.94      0.94       187\n",
            "\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Meta-Learner (Linear Regression) Accuracy: 0.26737967914438504\n",
            "Meta-Learner Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.77      0.79        31\n",
            "           1       0.17      0.81      0.28        32\n",
            "           2       0.00      0.00      0.00        36\n",
            "           3       0.00      0.00      0.00        27\n",
            "           4       0.00      0.00      0.00        29\n",
            "           5       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.27       187\n",
            "   macro avg       0.16      0.26      0.18       187\n",
            "weighted avg       0.16      0.27      0.18       187\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}